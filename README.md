# ğŸ¤– LLM Architecture Comparison - MVP

Projeto simplificado para comparaÃ§Ã£o rÃ¡pida entre arquiteturas RAG local vs APIs externas, focado em viabilidade tÃ©cnica e econÃ´mica para decisÃ£o executiva.

## ğŸ¯ Objetivo do MVP

Validar em **2 semanas** (40h) qual arquitetura Ã© mais adequada para o domÃ­nio de construÃ§Ã£o civil:
- **RAG Local**: Embeddings + FAISS + recuperaÃ§Ã£o simples
- **API Externa**: OpenAI/Claude com contexto

## ğŸš€ Quick Start

### 1. Setup Ambiente (Mac M1 otimizado)

```bash
# Clone o repositÃ³rio
git clone <repo>
cd otoh-llm-comparison

# Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # macOS/Linux

# Instale dependÃªncias essenciais
pip install -r requirements.txt

# Configure API keys (opcional)
echo "OPENAI_API_KEY=sua_key_aqui" > .env
```

### 2. ExecuÃ§Ã£o Completa do MVP

```bash
# Execute o pipeline completo
python run_mvp.py
```

Este comando irÃ¡:
1. âœ… Verificar ambiente
2. ğŸ“ Criar dados sintÃ©ticos de exemplo
3. ğŸ¤– Configurar RAG com embeddings
4. ğŸ§ª Testar RAG com 5 perguntas
5. ğŸŒ Testar API externa (se configurada)
6. ğŸ’° Calcular estimativas de custo
7. ğŸ“Š Gerar relatÃ³rio de comparaÃ§Ã£o

### 3. Visualizar Resultados

```bash
# LanÃ§ar dashboard interativo
streamlit run app/dashboard.py
```

Acesse: http://localhost:8501

## ğŸ“ Estrutura do Projeto

```
otoh-llm-comparison/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Documentos JSON (criados automaticamente)
â”‚   â”œâ”€â”€ embeddings/          # Ãndice FAISS + metadados
â”‚   â””â”€â”€ evaluation/          # Resultados e relatÃ³rios
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py           # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ simple_rag.py       # RAG simplificado (sÃ³ embeddings)
â”‚   â”œâ”€â”€ api_baseline.py     # Cliente APIs externas
â”‚   â””â”€â”€ evaluator.py        # MÃ©tricas e comparaÃ§Ãµes
â”œâ”€â”€ app/
â”‚   â””â”€â”€ dashboard.py        # Interface Streamlit
â”œâ”€â”€ requirements.txt        # DependÃªncias mÃ­nimas
â””â”€â”€ run_mvp.py             # Script principal
```

## ğŸ›ï¸ ConfiguraÃ§Ã£o

### Modelos Otimizados para MVP

- **Embedding**: `all-MiniLM-L6-v2` (rÃ¡pido, 22MB)
- **GeraÃ§Ã£o**: Apenas retrieval simples (sem LLM local)
- **API Externa**: GPT-3.5-turbo (custo-benefÃ­cio)

### Dados de Exemplo

O sistema cria automaticamente 5 documentos sobre:
- Normas de ruÃ­do (NBR 10151)
- EPIs obrigatÃ³rios
- Controle ambiental
- Obras noturnas
- Controle de qualidade

### Perguntas de Teste

5 perguntas cobrindo diferentes categorias:
1. Limites de ruÃ­do permitidos
2. Equipamentos de proteÃ§Ã£o obrigatÃ³rios
3. Controle de qualidade do concreto
4. Requisitos para obras noturnas
5. Quando fazer EIA/RIMA

## ğŸ“Š MÃ©tricas Avaliadas

### Quantitativas
- **Tempo de resposta** (segundos)
- **Custo por query** (USD)
- **Taxa de documentos relevantes** (%)
- **Cobertura de conceitos esperados** (%)

### Qualitativas (Manual)
- **PrecisÃ£o da resposta** (1-5)
- **Completude da informaÃ§Ã£o** (1-5)
- **Usabilidade geral** (1-5)

### CritÃ©rios de DecisÃ£o
- âœ… **< $0.10 por query**: ViÃ¡vel economicamente
- âœ… **< 3 segundos**: ExperiÃªncia aceitÃ¡vel  
- âœ… **> 70% relevÃ¢ncia**: Qualidade mÃ­nima
- âœ… **> 3.0/5.0 qualidade**: AprovaÃ§Ã£o usuÃ¡rios

## ğŸ’° AnÃ¡lise de Custos

### CenÃ¡rios Testados
- **Piloto**: 100 queries/dia
- **ProduÃ§Ã£o Pequena**: 1K queries/dia
- **ProduÃ§Ã£o MÃ©dia**: 5K queries/dia

### ComparaÃ§Ã£o Estimada
| Arquitetura | Setup | Custo/Query | Custo/MÃªs (1K/dia) |
|-------------|--------|-------------|---------------------|
| RAG Local   | $0     | ~$0.000     | ~$0                |
| OpenAI API  | $0     | ~$0.002     | ~$60               |

## ğŸ”§ Desenvolvimento

### Executar Componentes Individuais

```bash
# Apenas RAG
python src/simple_rag.py

# Apenas API baseline
python src/api_baseline.py

# Apenas avaliaÃ§Ã£o
python src/evaluator.py

# Validar configuraÃ§Ã£o
python -c "from src.config import Config; Config.validate_setup()"
```

### Estrutura de Dados

**Documento JSON:**
```json
{
  "id": "doc_001",
  "title": "Normas de RuÃ­do",
  "content": "O monitoramento de ruÃ­do...",
  "category": "regulamentacao",
  "keywords": ["ruÃ­do", "NBR 10151"]
}
```

**Resultado de Query:**
```json
{
  "question": "Quais os limites de ruÃ­do?",
  "answer": "Baseado no documento...",
  "response_time": 1.23,
  "relevance_score": 0.85,
  "retrieved_docs": 3
}
```

## ğŸ“ˆ Dashboard

### Abas DisponÃ­veis
1. **ğŸ“‹ Resumo Executivo**: RecomendaÃ§Ã£o + prÃ³ximos passos
2. **âš¡ Performance**: Tempo de resposta + taxa de sucesso
3. **ğŸ’° Custos**: ComparaÃ§Ã£o por cenÃ¡rio
4. **ğŸ¯ Qualidade**: AnÃ¡lise de relevÃ¢ncia + conceitos
5. **ğŸ” Detalhes**: Resultados completos por pergunta

### Funcionalidades
- ComparaÃ§Ã£o side-by-side
- Filtros por categoria/qualidade
- MÃ©tricas em tempo real
- Export de relatÃ³rios

## ğŸš¦ Troubleshooting

### Problemas Comuns

**1. Erro no PyTorch/MPS:**
```bash
# Force CPU se MPS der problema
export PYTORCH_ENABLE_MPS_FALLBACK=1
python run_mvp.py
```

**2. OpenAI API nÃ£o funciona:**
```bash
# Teste sem API (sÃ³ RAG)
export OPENAI_API_KEY=""
python run_mvp.py
```

**3. DependÃªncias faltando:**
```bash
# Reinstale requirements
pip install --upgrade -r requirements.txt
```

**4. FAISS nÃ£o instala:**
```bash
# Use versÃ£o CPU
pip install faiss-cpu --force-reinstall
```

### Logs Detalhados

```bash
# Debug completo
python -c "import logging; logging.basicConfig(level=logging.DEBUG)"
python run_mvp.py
```

## ğŸ“‹ Checklist MVP

### Semana 1 âœ…
- [x] Setup ambiente M1 compatÃ­vel
- [x] RAG bÃ¡sico funcional com 5 documentos
- [x] Testes automÃ¡ticos com 5 perguntas
- [x] API baseline (OpenAI + mock)
- [x] MÃ©tricas essenciais

### Semana 2 ğŸš§
- [x] Dashboard Streamlit
- [x] ComparaÃ§Ã£o automÃ¡tica
- [x] AnÃ¡lise de custos
- [x] RelatÃ³rio executivo
- [ ] Testes manuais de qualidade

## ğŸ¯ CritÃ©rio de Sucesso

**âœ… Stakeholder consegue decidir** entre RAG local vs API externa baseado em:
- Dados objetivos de performance
- AnÃ¡lise clara de custos
- RecomendaÃ§Ã£o justificada
- PrÃ³ximos passos definidos

## ğŸ”„ PrÃ³ximas IteraÃ§Ãµes

**Se MVP validar viabilidade:**
- Expandir para mais documentos reais
- Implementar fine-tuning com LoRA
- MÃ©tricas avanÃ§adas (ROUGE, BLEU)
- Pipeline automatizado CI/CD

**Se MVP mostrar inviabilidade:**
- Pivot para apenas APIs externas
- Foco em integraÃ§Ã£o/UX
- AnÃ¡lise detalhada de custos
- AvaliaÃ§Ã£o de outras arquiteturas

## ğŸ“ Suporte

Para problemas tÃ©cnicos:
1. Verifique logs em `logs/`
2. Execute `Config.validate_setup()`
3. Teste componentes individualmente
4. Consulte troubleshooting acima

---

**Tempo estimado total**: 15-30 minutos para setup + execuÃ§Ã£o completa
**Dados necessÃ¡rios**: Nenhum (usa dados sintÃ©ticos)
**DependÃªncias externas**: Apenas OpenAI API (opcional)
