# ðŸ¤– Sistema Multi-CenÃ¡rio RAG - ConstruÃ§Ã£o Civil

Sistema completo para comparaÃ§Ã£o entre trÃªs abordagens de NLP aplicadas ao domÃ­nio de construÃ§Ã£o civil, baseado nos artigos cientÃ­ficos mais recentes sobre RAG temporal e grafos dinÃ¢micos.

## ðŸ“š Base CientÃ­fica

Este projeto implementa conceitos dos seguintes artigos:

1. **DyG-RAG: Dynamic Graph Retrieval-Augmented Generation** - ImplementaÃ§Ã£o de grafos dinÃ¢micos com unidades de evento temporal
2. **StreamingRAG: Real-time Contextual Retrieval** - Processamento em tempo real de dados multimodais
3. **It's High Time: Temporal Information Retrieval** - TÃ©cnicas avanÃ§adas de recuperaÃ§Ã£o temporal
4. **When to use Graphs in RAG** - AnÃ¡lise comparativa GraphRAG vs RAG tradicional

## ðŸŽ¯ CenÃ¡rios Implementados

### ðŸ“Š CenÃ¡rio A: Vector-Only RAG
- **DescriÃ§Ã£o**: RAG tradicional usando apenas busca vetorial com embeddings temporais
- **Tecnologias**: SentenceTransformers + Fourier Time Encoding
- **Vantagens**: RÃ¡pido, simples, econÃ´mico
- **LimitaÃ§Ãµes**: NÃ£o considera relacionamentos complexos entre eventos

### ðŸ”— CenÃ¡rio B: Hybrid RAG (DyG-RAG + KÃ¹zu)
- **DescriÃ§Ã£o**: Sistema hÃ­brido inspirado no DyG-RAG, utilizando **KÃ¹zu Graph Database**
- **CaracterÃ­sticas**:
  - **Dynamic Event Units (DEUs)** com Ã¢ncoras temporais precisas
  - Grafo de eventos em KÃ¹zu com relacionamentos semÃ¢nticos e temporais
  - **Time Chain-of-Thought (Time-CoT)** para raciocÃ­nio temporal estruturado
  - RecuperaÃ§Ã£o multi-hop via consultas **openCypher**
  - **Fourier Time Encoding** para representaÃ§Ã£o temporal contÃ­nua
- **Vantagens**: RaciocÃ­nio temporal avanÃ§ado, alta precisÃ£o, arquitetura escalÃ¡vel
- **LimitaÃ§Ãµes**: Maior overhead computacional na construÃ§Ã£o do grafo

### ðŸ¤– CenÃ¡rio C: LLM-Only
- **DescriÃ§Ã£o**: LLM puro sem recuperaÃ§Ã£o de documentos
- **Vantagens**: Respostas fluidas, conhecimento generalista
- **LimitaÃ§Ãµes**: AlucinaÃ§Ãµes, dados desatualizados, sem acesso a contexto especÃ­fico

## ðŸ—ï¸ Arquitetura Implementada

```
src/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ events.py           # Dynamic Event Units (DEUs)
â”‚   â”œâ”€â”€ temporal_rag.py     # NetworkX-based DyG-RAG 
â”‚   â”œâ”€â”€ vector_rag.py       # Traditional Vector RAG
â”‚   â””â”€â”€ router.py           # Query complexity routing
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ time_utils.py       # Fourier Time Encoding
â”‚   â””â”€â”€ embeddings.py       # Semantic embeddings
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py          # Evaluation metrics
â”‚   â””â”€â”€ tests.py            # Unit tests
â””â”€â”€ pipelines/
    â”œâ”€â”€ ingestion.py        # Data ingestion pipeline
    â””â”€â”€ query.py            # Query processing pipeline

# IntegraÃ§Ã£o KÃ¹zu (Nova ImplementaÃ§Ã£o)
kuzu_integration.py         # KÃ¹zu Graph Database backend

# Script MVP Integrado
run_integrated_mvp.py       # ComparaÃ§Ã£o automatizada

# Dashboard Streamlit
app/dashboard.py            # VisualizaÃ§Ã£o interativa
```

## ðŸš€ Quick Start

### 1. ConfiguraÃ§Ã£o do Ambiente

```bash
# Crie o ambiente conda com todas as dependÃªncias
conda env create -f environment.yml
conda activate llm-comparison-multi

# Configure a API key da OpenAI (opcional - funciona com mocks)
echo "OPENAI_API_KEY=sua_key_aqui" > .env
```

### 2. ExecuÃ§Ã£o do MVP Integrado

```bash
# Executa comparaÃ§Ã£o completa entre os 3 cenÃ¡rios
python run_integrated_mvp.py
```

Este script irÃ¡:
- âœ… Gerar 150 eventos sintÃ©ticos de construÃ§Ã£o civil
- âœ… Configurar os sistemas Vector RAG e DyG-RAG
- âœ… Executar 5 perguntas de teste em todos os cenÃ¡rios
- âœ… Gerar mÃ©tricas comparativas de performance
- âœ… Salvar resultados em `data/evaluation/`

### 3. Dashboard Interativo

```bash
# Inicia o dashboard Streamlit
streamlit run app/dashboard.py
```

Acesse http://localhost:8501 para visualizar:
- ðŸ“Š GrÃ¡ficos comparativos de performance
- ðŸ” AnÃ¡lise detalhada por pergunta
- âš¡ MÃ©tricas de tempo de resposta e relevÃ¢ncia

## ðŸ”¬ ImplementaÃ§Ãµes TÃ©cnicas AvanÃ§adas

### Dynamic Event Units (DEUs)

Baseado no paper DyG-RAG, cada evento sonoro Ã© estruturado como:

```python
class DynamicEventUnit:
    event_id: str
    timestamp: datetime
    event_type: str          # martelo, serra, betoneira, etc.
    loudness: float          # Intensity em dB
    sensor_id: str
    description: Optional[str]
    metadata: Dict           # fase_obra, localizaÃ§Ã£o, equipamento
    
    def violates_noise_regulations(self) -> bool:
        # LÃ³gica baseada em horÃ¡rios e intensidade
        
    def to_embedding_text(self) -> str:
        # Texto otimizado para busca semÃ¢ntica
```

### Fourier Time Encoding

ImplementaÃ§Ã£o da codificaÃ§Ã£o temporal contÃ­nua do DyG-RAG:

```python
class FourierTimeEncoder:
    def encode(self, dt: datetime) -> np.ndarray:
        # Gera representaÃ§Ã£o periÃ³dica suave do tempo
        # Captura padrÃµes diÃ¡rios, semanais, sazonais
```

### Time Chain-of-Thought (Time-CoT)

RaciocÃ­nio temporal estruturado em 6 etapas:

1. **Identificar escopo temporal** da pergunta
2. **Filtrar eventos** no escopo identificado  
3. **Analisar ordem cronolÃ³gica** dos eventos
4. **Inferir persistÃªncia de estados** temporais
5. **Verificar consistÃªncia** com regulamentaÃ§Ãµes
6. **Gerar sugestÃ£o** baseada na cadeia de raciocÃ­nio

### IntegraÃ§Ã£o KÃ¹zu Graph Database

Sistema de grafo temporal escalÃ¡vel usando openCypher:

```cypher
# Exemplo: Busca por padrÃµes sequenciais
MATCH (e1:Event)-[r:TemporalRelation]->(e2:Event)
WHERE r.time_diff_seconds <= 1800
RETURN e1.event_type, e2.event_type, COUNT(*) as frequency
ORDER BY frequency DESC
```

## ðŸ“Š Resultados Esperados

Com base nos papers de referÃªncia, esperamos:

### Performance (Tempo de Resposta)
1. **LLM-Only**: ~50ms (mais rÃ¡pido)
2. **Vector RAG**: ~200ms (intermediÃ¡rio)  
3. **DyG-RAG**: ~800ms (mais lento, mais preciso)

### RelevÃ¢ncia (Score de Qualidade)
1. **DyG-RAG**: ~0.85 (melhor para anÃ¡lises complexas)
2. **Vector RAG**: ~0.72 (bom para buscas simples)
3. **LLM-Only**: ~0.60 (limitado sem contexto)

### Trade-offs Identificados
- **Consultas Simples**: Vector RAG Ã© suficiente e mais eficiente
- **AnÃ¡lises Complexas**: DyG-RAG oferece vantagem significativa
- **Respostas Gerais**: LLM-Only para conhecimento base

## ðŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### ParÃ¢metros do Sistema

```python
# config/settings.py
TIME_WINDOW = 300           # Janela temporal (segundos)
TIME_EMBEDDING_DIM = 64     # Dimensionalidade temporal
SIMILARITY_THRESHOLD = 0.7  # Threshold semÃ¢ntico
```

### PersonalizaÃ§Ã£o de Dados

Para usar seus prÃ³prios dados de eventos sonoros:

```python
# Formato CSV esperado
# timestamp,event_type,loudness,sensor_id,description,phase,location
```

## ðŸ§ª Testes e AvaliaÃ§Ã£o

```bash
# Executa suite de testes
python -m pytest src/evaluation/tests.py -v

# AnÃ¡lise de coverage
pytest --cov=src src/evaluation/tests.py
```

## ðŸ“ˆ Monitoramento

O sistema inclui mÃ©tricas detalhadas:
- Tempo de resposta por cenÃ¡rio
- Qualidade da recuperaÃ§Ã£o (Precision/Recall)
- EstatÃ­sticas do grafo temporal
- DetecÃ§Ã£o de violaÃ§Ãµes de ruÃ­do

## ðŸš€ Deploy

O sistema estÃ¡ preparado para:
- **AWS Neptune** (substituir KÃ¹zu para produÃ§Ã£o)
- **Docker containers** 
- **API REST** via FastAPI
- **Monitoring** com Prometheus

## ðŸ“ PrÃ³ximos Passos

1. **IntegraÃ§Ã£o com dados reais** de sensores IoT
2. **Fine-tuning** de embeddings para domÃ­nio especÃ­fico
3. **OtimizaÃ§Ã£o** de consultas KÃ¹zu para grandes volumes
4. **Dashboard** de monitoramento em tempo real
5. **API** para integraÃ§Ã£o com sistemas externos

## ðŸ¤ ContribuiÃ§Ã£o

Este projeto implementa tÃ©cnicas de ponta em RAG temporal. ContribuiÃ§Ãµes sÃ£o bem-vindas especialmente em:

- OtimizaÃ§Ã£o de performance do grafo dinÃ¢mico
- Novos algoritmos de Time-CoT
- IntegraÃ§Ã£o com mais tipos de sensores
- MÃ©tricas de avaliaÃ§Ã£o mais sofisticadas

## ðŸ“„ LicenÃ§a

MIT License - Veja [LICENSE](LICENSE) para detalhes.

---

*Baseado nos papers: DyG-RAG (Sun et al., 2025), StreamingRAG (Sankaradas et al., 2024), Temporal IR Survey (Piryani et al., 2025), GraphRAG Analysis (Xiang et al., 2025)*