#!/usr/bin/env python3
"""
MVP Runner - LLM Architecture Comparison
Script simplificado para valida√ß√£o r√°pida da abordagem

Execute com: python run_mvp.py
"""

import os
import sys
import json
import time
import logging
from pathlib import Path
from typing import Dict, List, Any
import pandas as pd

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def check_environment():
    """Verifica ambiente b√°sico"""
    logger.info("üîç Verificando ambiente...")
    
    try:
        import torch
        import transformers
        import sentence_transformers
        import faiss
        import streamlit
        logger.info("‚úÖ Depend√™ncias principais encontradas")
        return True
    except ImportError as e:
        logger.error(f"‚ùå Depend√™ncia faltando: {e}")
        logger.error("Execute: pip install -r requirements.txt")
        return False

def create_sample_data():
    """Cria dados de exemplo para o MVP"""
    logger.info("üìù Criando dados de exemplo...")
    
    data_dir = Path("data/raw")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # Dados sint√©ticos sobre constru√ß√£o civil
    sample_docs = [
        {
            "id": "doc_001",
            "title": "Normas de Ru√≠do - NBR 10151",
            "content": "O monitoramento de ru√≠do em obras urbanas deve seguir as diretrizes da NBR 10151. Os n√≠veis de ru√≠do n√£o podem exceder 70 dB durante o dia e 60 dB durante a noite em √°reas residenciais. √â obrigat√≥rio o uso de medidores calibrados e registros hor√°rios. A medi√ß√£o deve ser feita no limite da propriedade mais pr√≥xima aos receptores sens√≠veis.",
            "category": "regulamentacao",
            "keywords": ["ru√≠do", "NBR 10151", "medi√ß√£o", "limites", "obras urbanas"]
        },
        {
            "id": "doc_002", 
            "title": "EPIs Obrigat√≥rios em Canteiros",
            "content": "Equipamentos de prote√ß√£o individual (EPIs) obrigat√≥rios em canteiros incluem: capacete de seguran√ßa classe A ou B, √≥culos de prote√ß√£o contra impactos, luvas adequadas ao tipo de atividade, cal√ßados de seguran√ßa com biqueira de a√ßo, cintos de seguran√ßa para trabalho em altura acima de 2 metros. A empresa deve fornecer gratuitamente e treinar os trabalhadores sobre o uso correto.",
            "category": "seguranca",
            "keywords": ["EPIs", "capacete", "√≥culos", "luvas", "cal√ßados", "cintos", "treinamento"]
        },
        {
            "id": "doc_003",
            "title": "Controle de Impacto Ambiental",
            "content": "O controle de impacto ambiental em constru√ß√µes requer licenciamento pr√©vio do √≥rg√£o competente, elabora√ß√£o de plano de gerenciamento de res√≠duos s√≥lidos, implementa√ß√£o de medidas de controle de eros√£o e prote√ß√£o de recursos h√≠dricos. Obras com √°rea superior a 3000m¬≤ necessitam de estudo de impacto ambiental (EIA/RIMA).",
            "category": "meio_ambiente", 
            "keywords": ["licenciamento", "res√≠duos", "eros√£o", "recursos h√≠dricos", "EIA", "RIMA"]
        },
        {
            "id": "doc_004",
            "title": "Obras Noturnas - Regulamenta√ß√£o",
            "content": "Obras noturnas requerem autoriza√ß√£o especial da prefeitura municipal, ilumina√ß√£o adequada com intensidade m√≠nima de 200 lux, sinaliza√ß√£o refor√ßada com dispositivos refletivos e luminosos, equipes especializadas com treinamento em seguran√ßa noturna. O hor√°rio permitido varia entre 22h e 6h, dependendo da classifica√ß√£o da √°rea urbana.",
            "category": "regulamentacao",
            "keywords": ["obras noturnas", "autoriza√ß√£o", "ilumina√ß√£o", "200 lux", "sinaliza√ß√£o", "22h-6h"]
        },
        {
            "id": "doc_005",
            "title": "Controle de Qualidade do Concreto",
            "content": "O controle de qualidade em constru√ß√£o envolve inspe√ß√µes regulares dos materiais, realiza√ß√£o de ensaios de resist√™ncia √† compress√£o, documenta√ß√£o completa de todos os procedimentos e auditorias internas peri√≥dicas. Para concreto estrutural, devem ser realizados ensaios a cada 50m¬≥ ou a cada dia de concretagem, prevalecendo o menor valor.",
            "category": "qualidade",
            "keywords": ["controle qualidade", "inspe√ß√µes", "ensaios", "concreto", "50m¬≥", "resist√™ncia"]
        }
    ]
    
    # Salva documentos individuais
    for doc in sample_docs:
        doc_file = data_dir / f"{doc['id']}.json"
        with open(doc_file, 'w', encoding='utf-8') as f:
            json.dump(doc, f, ensure_ascii=False, indent=2)
    
    logger.info(f"‚úÖ Criados {len(sample_docs)} documentos em {data_dir}")
    return sample_docs

def create_test_questions():
    """Cria perguntas de teste para avalia√ß√£o"""
    test_questions = [
        {
            "id": "q001",
            "question": "Quais s√£o os limites de ru√≠do permitidos em obras urbanas?",
            "expected_concepts": ["70 dB", "60 dB", "NBR 10151", "dia", "noite"],
            "category": "regulamentacao"
        },
        {
            "id": "q002", 
            "question": "Que equipamentos de prote√ß√£o s√£o obrigat√≥rios em canteiros de obra?",
            "expected_concepts": ["capacete", "√≥culos", "luvas", "cal√ßados", "cintos"],
            "category": "seguranca"
        },
        {
            "id": "q003",
            "question": "Como deve ser feito o controle de qualidade do concreto?",
            "expected_concepts": ["50m¬≥", "ensaios", "resist√™ncia", "dia de concretagem"],
            "category": "qualidade"
        },
        {
            "id": "q004",
            "question": "Quais s√£o os requisitos para obras noturnas?",
            "expected_concepts": ["autoriza√ß√£o", "200 lux", "22h", "6h", "sinaliza√ß√£o"],
            "category": "regulamentacao"
        },
        {
            "id": "q005",
            "question": "Quando √© necess√°rio fazer EIA/RIMA para uma obra?", 
            "expected_concepts": ["3000m¬≤", "estudo de impacto", "licenciamento"],
            "category": "meio_ambiente"
        }
    ]
    
    # Salva perguntas de teste
    questions_file = Path("data/evaluation/test_questions.json")
    questions_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(questions_file, 'w', encoding='utf-8') as f:
        json.dump(test_questions, f, ensure_ascii=False, indent=2)
    
    logger.info(f"‚úÖ Criadas {len(test_questions)} perguntas de teste")
    return test_questions

def setup_rag_simple():
    """Configura RAG simples com modelo leve"""
    logger.info("ü§ñ Configurando RAG simples...")
    
    try:
        from sentence_transformers import SentenceTransformer
        import faiss
        import numpy as np
        
        # Carrega documentos
        data_dir = Path("data/raw")
        documents = []
        
        for json_file in data_dir.glob("*.json"):
            with open(json_file, 'r', encoding='utf-8') as f:
                doc = json.load(f)
                documents.append(doc)
        
        if not documents:
            logger.error("‚ùå Nenhum documento encontrado")
            return False
        
        # Modelo de embedding leve
        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Cria embeddings
        texts = [doc['content'] for doc in documents]
        embeddings = embedding_model.encode(texts, show_progress_bar=True)
        
        # Cria √≠ndice FAISS
        dimension = embeddings.shape[1]
        index = faiss.IndexFlatL2(dimension)
        index.add(embeddings.astype('float32'))
        
        # Salva √≠ndice e metadados
        embeddings_dir = Path("data/embeddings")
        embeddings_dir.mkdir(parents=True, exist_ok=True)
        
        faiss.write_index(index, str(embeddings_dir / "index.faiss"))
        
        # Salva documentos para recupera√ß√£o
        docs_df = pd.DataFrame(documents)
        docs_df.to_json(embeddings_dir / "documents.json", orient='records', indent=2)
        
        logger.info(f"‚úÖ RAG configurado: {len(documents)} docs, dimens√£o {dimension}")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro no setup RAG: {e}")
        return False

def test_rag_basic():
    """Testa RAG b√°sico com perguntas simples"""
    logger.info("üß™ Testando RAG b√°sico...")
    
    try:
        from sentence_transformers import SentenceTransformer
        import faiss
        import pandas as pd
        
        # Carrega √≠ndice
        embeddings_dir = Path("data/embeddings") 
        index = faiss.read_index(str(embeddings_dir / "index.faiss"))
        docs_df = pd.read_json(embeddings_dir / "documents.json", orient='records')
        documents = docs_df.to_dict('records')
        
        # Carrega modelo
        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Carrega perguntas
        with open("data/evaluation/test_questions.json", 'r', encoding='utf-8') as f:
            test_questions = json.load(f)
        
        results = []
        
        for q in test_questions:
            start_time = time.time()
            
            # Busca documentos relevantes
            query_embedding = embedding_model.encode([q['question']])
            scores, indices = index.search(query_embedding.astype('float32'), k=3)
            
            # Recupera documentos
            retrieved_docs = []
            for score, idx in zip(scores[0], indices[0]):
                if idx < len(documents):
                    doc = documents[idx].copy()
                    doc['relevance_score'] = float(score)
                    retrieved_docs.append(doc)
            
            response_time = time.time() - start_time
            
            # Resposta simples (concatena conte√∫do dos docs mais relevantes)
            if retrieved_docs:
                answer = retrieved_docs[0]['content'][:200] + "..."
                relevance = 1.0 / (1.0 + retrieved_docs[0]['relevance_score'])  # Converte dist√¢ncia em relev√¢ncia
            else:
                answer = "Nenhum documento relevante encontrado."
                relevance = 0.0
            
            result = {
                'question_id': q['id'],
                'question': q['question'],
                'answer': answer,
                'response_time': response_time,
                'relevance_score': relevance,
                'retrieved_docs': len(retrieved_docs)
            }
            
            results.append(result)
            
            logger.info(f"Q{q['id']}: {response_time:.2f}s, relev√¢ncia: {relevance:.3f}")
        
        # Salva resultados
        results_file = Path("data/evaluation/rag_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # M√©tricas agregadas
        avg_time = sum(r['response_time'] for r in results) / len(results)
        avg_relevance = sum(r['relevance_score'] for r in results) / len(results)
        
        logger.info(f"‚úÖ RAG testado: {avg_time:.2f}s m√©dio, relev√¢ncia {avg_relevance:.3f}")
        
        return results
        
    except Exception as e:
        logger.error(f"‚ùå Erro no teste RAG: {e}")
        return []

def estimate_costs():
    """Estima custos b√°sicos para diferentes cen√°rios"""
    logger.info("üí∞ Estimando custos...")
    
    scenarios = [
        {"name": "Piloto", "queries_per_day": 100},
        {"name": "Produ√ß√£o Pequena", "queries_per_day": 1000}, 
        {"name": "Produ√ß√£o M√©dia", "queries_per_day": 5000}
    ]
    
    # Custos aproximados (USD)
    costs = {
        "rag_local": {
            "setup_cost": 0,  # Usando hardware existente
            "cost_per_1k_queries": 0.01,  # Apenas eletricidade/desgaste
            "monthly_fixed": 0
        },
        "openai_api": {
            "setup_cost": 0,
            "cost_per_1k_queries": 2.00,  # GPT-3.5-turbo aproximado
            "monthly_fixed": 0
        }
    }
    
    results = []
    
    for scenario in scenarios:
        monthly_queries = scenario["queries_per_day"] * 30
        
        for arch, cost_config in costs.items():
            monthly_cost = (
                cost_config["monthly_fixed"] + 
                (monthly_queries / 1000) * cost_config["cost_per_1k_queries"]
            )
            
            annual_cost = cost_config["setup_cost"] + (monthly_cost * 12)
            
            results.append({
                "scenario": scenario["name"],
                "architecture": arch,
                "queries_per_day": scenario["queries_per_day"],
                "monthly_cost_usd": monthly_cost,
                "annual_cost_usd": annual_cost,
                "cost_per_query_usd": monthly_cost / monthly_queries if monthly_queries > 0 else 0
            })
    
    # Salva estimativas
    costs_file = Path("data/evaluation/cost_estimates.json")
    with open(costs_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    logger.info("‚úÖ Custos estimados salvos")
    return results

def generate_summary_report():
    """Gera relat√≥rio sum√°rio do MVP""" 
    logger.info("üìã Gerando relat√≥rio sum√°rio...")
    
    try:
        # Carrega resultados
        rag_results = []
        costs = []
        
        rag_file = Path("data/evaluation/rag_results.json")
        if rag_file.exists():
            with open(rag_file, 'r', encoding='utf-8') as f:
                rag_results = json.load(f)
        
        costs_file = Path("data/evaluation/cost_estimates.json")
        if costs_file.exists():
            with open(costs_file, 'r', encoding='utf-8') as f:
                costs = json.load(f)
        
        # M√©tricas agregadas RAG
        if rag_results:
            avg_time = sum(r['response_time'] for r in rag_results) / len(rag_results)
            avg_relevance = sum(r['relevance_score'] for r in rag_results) / len(rag_results)
        else:
            avg_time, avg_relevance = 0, 0
        
        report = {
            "mvp_summary": {
                "execution_date": time.strftime("%Y-%m-%d %H:%M:%S"),
                "total_test_questions": len(rag_results),
                "rag_performance": {
                    "avg_response_time_sec": round(avg_time, 2),
                    "avg_relevance_score": round(avg_relevance, 3),
                    "success_rate": len([r for r in rag_results if r['relevance_score'] > 0.1]) / len(rag_results) if rag_results else 0
                },
                "cost_analysis": costs
            },
            "recommendations": {
                "for_pilot": "RAG local se < 500 queries/dia",
                "for_production": "Avaliar APIs externas se > 1000 queries/dia",
                "next_steps": [
                    "Testar com mais documentos reais",
                    "Implementar interface usu√°rio", 
                    "Avaliar qualidade respostas manualmente",
                    "Decidir entre arquiteturas"
                ]
            },
            "technical_notes": {
                "embedding_model": "all-MiniLM-L6-v2",
                "vector_search": "FAISS",
                "limitations": [
                    "Apenas 5 documentos teste",
                    "Sem modelo gera√ß√£o pr√≥prio",
                    "M√©tricas b√°sicas apenas"
                ]
            }
        }
        
        # Salva relat√≥rio
        report_file = Path("data/evaluation/mvp_summary_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ Relat√≥rio salvo em {report_file}")
        return report
        
    except Exception as e:
        logger.error(f"‚ùå Erro no relat√≥rio: {e}")
        return {}

def main():
    """Fun√ß√£o principal do MVP"""
    logger.info("üöÄ EXECUTANDO MVP - LLM COMPARISON")
    logger.info("="*50)
    
    # Passo 1: Verificar ambiente
    if not check_environment():
        logger.error("‚ùå Ambiente n√£o configurado. Execute: pip install -r requirements.txt")
        return False
    
    # Passo 2: Validar configura√ß√£o
    sys.path.append('src')
    from config import Config
    
    if not Config.validate_setup():
        logger.error("‚ùå Configura√ß√£o inv√°lida")
        return False
    
    # Passo 3: Criar dados de exemplo
    sample_docs = create_sample_data()
    test_questions = create_test_questions()
    
    # Passo 4: Setup RAG
    if not setup_rag_simple():
        logger.error("‚ùå Falha no setup RAG")
        return False
    
    # Passo 5: Testar RAG
    rag_results = test_rag_basic()
    if not rag_results:
        logger.error("‚ùå Falha nos testes RAG")
        return False
    
    # Passo 6: Estimar custos
    cost_estimates = estimate_costs()
    
    # Passo 7: Gerar relat√≥rio
    report = generate_summary_report()
    
    # Resumo final
    logger.info("\n" + "="*50)
    logger.info("üéâ MVP CONCLU√çDO COM SUCESSO!")
    logger.info("="*50)
    
    if rag_results:
        avg_time = sum(r['response_time'] for r in rag_results) / len(rag_results)
        avg_relevance = sum(r['relevance_score'] for r in rag_results) / len(rag_results)
        
        logger.info(f"üìä Resultados RAG:")
        logger.info(f"   ‚Ä¢ Tempo m√©dio: {avg_time:.2f}s")
        logger.info(f"   ‚Ä¢ Relev√¢ncia m√©dia: {avg_relevance:.3f}")
        logger.info(f"   ‚Ä¢ Perguntas testadas: {len(rag_results)}")
    
    if cost_estimates:
        logger.info(f"üí∞ Custos estimados:")
        for cost in cost_estimates[:3]:  # Primeiros 3 cen√°rios
            logger.info(f"   ‚Ä¢ {cost['scenario']}: ${cost['monthly_cost_usd']:.2f}/m√™s")
    
    logger.info(f"\nüìã Pr√≥ximos passos:")
    logger.info(f"   1. Execute: streamlit run app/dashboard.py")
    logger.info(f"   2. Avalie resultados manualmente")
    logger.info(f"   3. Decida pr√≥xima arquitetura")
    
    return True

if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1)
        